#output_dir: ./outputs

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled
  - override hydra/launcher: submitit_slurm

hydra:
  output_subdir: null
  # mode: MULTIRUN
  # launcher:
  #   max_num_timeout: 999
  #   gpus_per_node: 2
  #   tasks_per_node: ${hydra.launcher.gpus_per_node}
  #   cpus_per_task: 4
  #   mem_gb: 48
  #   timeout_min: 4600
  #   partition: main
  #   signal_delay_s: 120
  #   constraint: lovelace
  #   # setup:
  #   [
  #     "tar -czf \"$SLURM_TMPDIR/stablewm.tgz\" -C \"$STABLEWM_HOME\" .",
  #     "tar -xzf \"$SLURM_TMPDIR/stablewm.tgz\" -C \"$SLURM_TMPDIR\"",
  #     "rm -f \"$SLURM_TMPDIR/stablewm.tgz\""
  #   ]
  run:
    dir: .

wandb:
  enable: true
  project: xenoworlds
  entity: simon-lacoste-julien

dataset_name: pusht_expert
# cache_dir: null #${oc.env:SLURM_TMPDIR, null}
output_model_name: world_model

trainer:
  max_epochs: 100
  strategy: ddp
  devices: auto
  accelerator: gpu
  precision: 16-mixed

batch_size: 64
num_workers: 8
train_split: 0.9

image_size: 224
patch_size: 16

n_steps: 2
frameskip: 5

dinowm:
  history_size: 3
  num_preds: 1
  proprio_dim: 4
  proprio_embed_dim: 10
  action_dim: 2
  action_embed_dim: 10

predictor:
  depth: 6
  heads: 16
  mlp_dim: 2048
  dim_head: 64
  dropout: 0.1
  emb_dropout: 0.0

predictor_lr: 5e-4
proprio_encoder_lr: 5e-4
action_encoder_lr: 5e-4

dump_object: True
